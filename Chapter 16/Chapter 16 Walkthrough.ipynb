{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 16:Training neural networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Classifying data with neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16.1 Classifying images of handwritten digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.1.1 Building the 64-dimensional image vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2770d53d490>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAKpElEQVR4nO3dX4hc9RnG8efpqrRWo7EJRbKhm4AEpFATl4CkCI1siVW0F1USUKgUvKmitGC0d73TG7EXRZCoFUyVbFQQsVpBpRVa624SW5PVksSUbNAmoRH/XDRE317sCURZ3TNnzr99+/3A4s7usL93SL6emdmT83NECEAeX+t6AAD1ImogGaIGkiFqIBmiBpI5q4kfumzZshgbG2viR3fqxIkTra43Ozvb2lpLlixpba3R0dHW1hoZGWltrTYdOnRIx48f93zfayTqsbExTU1NNfGjOzU5Odnqelu3bm1trYmJidbWuvfee1tba+nSpa2t1abx8fEv/R5Pv4FkiBpIhqiBZIgaSIaogWSIGkiGqIFkiBpIhqiBZEpFbXuT7Xds77d9d9NDAahuwahtj0j6raSrJV0qaYvtS5seDEA1ZY7U6yXtj4iDEXFS0pOSrm92LABVlYl6haTDZ9yeLb72ObZvtT1le+rYsWN1zQdgQLW9URYRD0XEeESML1++vK4fC2BAZaI+ImnlGbdHi68B6KEyUb8h6RLbq2yfI2mzpGebHQtAVQteJCEiTtm+TdKLkkYkPRIRexufDEAlpa58EhHPS3q+4VkA1IAzyoBkiBpIhqiBZIgaSIaogWSIGkiGqIFkGtmhI6s2d8yQpHfffbe1tdrcUuiiiy5qba0dO3a0tpYk3XDDDa2uNx+O1EAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJFNmh45HbB+1/VYbAwEYTpkj9e8kbWp4DgA1WTDqiPiTpP+0MAuAGtT2mpptd4B+YNsdIBne/QaSIWogmTK/0npC0l8krbE9a/tnzY8FoKoye2ltaWMQAPXg6TeQDFEDyRA1kAxRA8kQNZAMUQPJEDWQzKLfdmd6erq1tdrcBkeSDhw40Npaq1evbm2tiYmJ1tZq8++HxLY7ABpA1EAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMmWuUbbS9iu299nea/uONgYDUE2Zc79PSfplROyyfb6kadsvRcS+hmcDUEGZbXfei4hdxecfSZqRtKLpwQBUM9BrattjktZKen2e77HtDtADpaO2fZ6kpyTdGREffvH7bLsD9EOpqG2frbmgt0fE082OBGAYZd79tqSHJc1ExP3NjwRgGGWO1Bsk3Sxpo+09xcePGp4LQEVltt15TZJbmAVADTijDEiGqIFkiBpIhqiBZIgaSIaogWSIGkiGqIFkFv1eWidOnGhtrXXr1rW2ltTu/lZtuvzyy7seITWO1EAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMmUuPPh123+z/Wax7c6v2xgMQDVlThP9r6SNEfFxcang12z/ISL+2vBsACooc+HBkPRxcfPs4iOaHApAdWUv5j9ie4+ko5Jeigi23QF6qlTUEfFpRFwmaVTSetvfnec+bLsD9MBA735HxAeSXpG0qZFpAAytzLvfy21fWHz+DUkTkt5ueC4AFZV59/tiSY/ZHtHc/wR2RMRzzY4FoKoy737/XXN7UgNYBDijDEiGqIFkiBpIhqiBZIgaSIaogWSIGkiGqIFk2HZnABMTE62tlVmbf2ZLly5tba2+4EgNJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAypaMuLui/2zYXHQR6bJAj9R2SZpoaBEA9ym67MyrpGknbmh0HwLDKHqkfkHSXpM++7A7spQX0Q5kdOq6VdDQipr/qfuylBfRDmSP1BknX2T4k6UlJG20/3uhUACpbMOqIuCciRiNiTNJmSS9HxE2NTwagEn5PDSQz0OWMIuJVSa82MgmAWnCkBpIhaiAZogaSIWogGaIGkiFqIBmiBpJZ9NvutLmtyvT0V57+vqi1uRXO1NRUa2vdeOONra3VFxypgWSIGkiGqIFkiBpIhqiBZIgaSIaogWSIGkiGqIFkiBpIptRposWVRD+S9KmkUxEx3uRQAKob5NzvH0TE8cYmAVALnn4DyZSNOiT90fa07VvnuwPb7gD9UDbq70fEOklXS/q57Su/eAe23QH6oVTUEXGk+O9RSc9IWt/kUACqK7NB3jdtn3/6c0k/lPRW04MBqKbMu9/flvSM7dP3/31EvNDoVAAqWzDqiDgo6XstzAKgBvxKC0iGqIFkiBpIhqiBZIgaSIaogWSIGkhm0W+7s3r16tbWanO7GEmanJxMuVabtm7d2vUIreNIDSRD1EAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMqWitn2h7Z2237Y9Y/uKpgcDUE3Zc79/I+mFiPiJ7XMkndvgTACGsGDUti+QdKWkn0pSRJyUdLLZsQBUVebp9ypJxyQ9anu37W3F9b8/h213gH4oE/VZktZJejAi1kr6RNLdX7wT2+4A/VAm6llJsxHxenF7p+YiB9BDC0YdEe9LOmx7TfGlqyTta3QqAJWVfff7dknbi3e+D0q6pbmRAAyjVNQRsUfSeLOjAKgDZ5QByRA1kAxRA8kQNZAMUQPJEDWQDFEDyRA1kAx7aQ3gvvvua20tqd19oMbH2zu3aHp6urW1/h9xpAaSIWogGaIGkiFqIBmiBpIhaiAZogaSIWogGaIGklkwattrbO854+ND23e2MBuAChY8TTQi3pF0mSTZHpF0RNIzzY4FoKpBn35fJelARPyriWEADG/QqDdLemK+b7DtDtAPpaMurvl9naTJ+b7PtjtAPwxypL5a0q6I+HdTwwAY3iBRb9GXPPUG0B+loi62rp2Q9HSz4wAYVtltdz6R9K2GZwFQA84oA5IhaiAZogaSIWogGaIGkiFqIBmiBpIhaiAZR0T9P9Q+JmnQf565TNLx2ofph6yPjcfVne9ExLz/cqqRqKuwPRUR7W3o1KKsj43H1U88/QaSIWogmT5F/VDXAzQo62PjcfVQb15TA6hHn47UAGpA1EAyvYja9ibb79jeb/vuruepg+2Vtl+xvc/2Xtt3dD1TnWyP2N5t+7muZ6mT7Qtt77T9tu0Z21d0PdOgOn9NXWwQ8E/NXS5pVtIbkrZExL5OBxuS7YslXRwRu2yfL2la0o8X++M6zfYvJI1LWhIR13Y9T11sPybpzxGxrbiC7rkR8UHHYw2kD0fq9ZL2R8TBiDgp6UlJ13c809Ai4r2I2FV8/pGkGUkrup2qHrZHJV0jaVvXs9TJ9gWSrpT0sCRFxMnFFrTUj6hXSDp8xu1ZJfnLf5rtMUlrJb3e8Sh1eUDSXZI+63iOuq2SdEzSo8VLi23FRTcXlT5EnZrt8yQ9JenOiPiw63mGZftaSUcjYrrrWRpwlqR1kh6MiLWSPpG06N7j6UPURyStPOP2aPG1Rc/22ZoLentEZLm88gZJ19k+pLmXShttP97tSLWZlTQbEaefUe3UXOSLSh+ifkPSJbZXFW9MbJb0bMczDc22NffabCYi7u96nrpExD0RMRoRY5r7s3o5Im7qeKxaRMT7kg7bXlN86SpJi+6NzVLX/W5SRJyyfZukFyWNSHokIvZ2PFYdNki6WdI/bO8pvvariHi+u5FQwu2SthcHmIOSbul4noF1/istAPXqw9NvADUiaiAZogaSIWogGaIGkiFqIBmiBpL5H9Sir9XgxKzrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[0], cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FYI, a way to overlay numbers on the pixels showing their brightness values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[0], cmap=plt.cm.gray_r)\n",
    "for i in range(0,8):\n",
    "    for j in range(0,8):\n",
    "        plt.gca().text(i-0.15,j,int(digits.images[0][i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matrix.flatten(digits.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.33333333, 0.86666667, 0.6       ,\n",
       "       0.06666667, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.86666667, 1.        , 0.66666667, 1.        , 0.33333333,\n",
       "       0.        , 0.        , 0.2       , 1.        , 0.13333333,\n",
       "       0.        , 0.73333333, 0.53333333, 0.        , 0.        ,\n",
       "       0.26666667, 0.8       , 0.        , 0.        , 0.53333333,\n",
       "       0.53333333, 0.        , 0.        , 0.33333333, 0.53333333,\n",
       "       0.        , 0.        , 0.6       , 0.53333333, 0.        ,\n",
       "       0.        , 0.26666667, 0.73333333, 0.        , 0.06666667,\n",
       "       0.8       , 0.46666667, 0.        , 0.        , 0.13333333,\n",
       "       0.93333333, 0.33333333, 0.66666667, 0.8       , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.4       , 0.86666667,\n",
       "       0.66666667, 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matrix.flatten(digits.images[0]) / 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.1.2 Building a random digit classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_classifier(input_vector):\n",
    "    return np.random.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56068348, 0.56269168, 0.89048511, 0.32813939, 0.96546431,\n",
       "       0.84635534, 0.12640797, 0.40012519, 0.16221877, 0.84566599])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.matrix.flatten(digits.images[0]) / 15.\n",
    "result = random_classifier(v)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** because this is random, you will get a different digit result when you re-run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(result).index(max(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.1.3 Measuring performance of the digit classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_digit_classify(classifier,test_count=1000):\n",
    "    correct = 0 #<1>\n",
    "    for img, target in zip(digits.images[:test_count], digits.target[:test_count]): #<2>\n",
    "        v = np.matrix.flatten(img) / 15. #<3>\n",
    "        output = classifier(v) #<4>\n",
    "        answer = list(output).index(max(output)) #<5>\n",
    "        if answer == target:\n",
    "            correct += 1 #<6>\n",
    "    return (correct/test_count) #<7>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.091"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digit_classify(random_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.1.4 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Suppose a digit classifier function outputs the following NumPy array.  What digit does it think the image represents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.00512567e-06, 3.94168539e-05, 5.57124430e-09, 9.31981207e-09,\n",
       "       9.98060276e-01, 9.10328786e-07, 1.56262695e-03, 1.82976466e-04,\n",
       "       1.48519455e-04, 2.54354113e-07])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([5.00512567e-06, 3.94168539e-05, 5.57124430e-09, 9.31981207e-09,\n",
    "       9.98060276e-01, 9.10328786e-07, 1.56262695e-03, 1.82976466e-04,\n",
    "       1.48519455e-04, 2.54354113e-07])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mini project:** Find the average of all the images of nines in the data set, in the same way we took averages of images in Chapter 6.  Plot the resulting image. What does it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_img(i):\n",
    "    imgs = [img for img,target in zip(digits.images[1000:], digits.target[1000:]) if target==i]\n",
    "    return sum(imgs) / len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2770d205550>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(average_img(9), cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mini project:** Build a better classifier than a random one by finding the average image of each kind of digit in the test data set, and comparing a target image with all of the averages.  Specifically, return a vector of the dot products of the target image with each average digit image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_digits = [np.matrix.flatten(average_img(i)) for i in range(10)]\n",
    "def compare_to_avg(v):\n",
    "    return [np.dot(v,avg_digits[i]) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.853"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digit_classify(compare_to_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16.2 Designing a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2.1 Organizing neurons and connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2.2 Data flow through a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2.3 Calculating activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2.4 Calculating activations in matrix notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2.5 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16.3 Building a neural network in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.3.1 Implementing an MLP class in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP():\n",
    "    def __init__(self,layer_sizes): #<1>\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.weights = [\n",
    "            np.random.rand(n,m) #<2>\n",
    "            for m,n in zip(layer_sizes[:-1],layer_sizes[1:]) #<3>\n",
    "        ]\n",
    "        self.biases = [np.random.rand(n) for n in layer_sizes[1:]] #<4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLP([2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** these numbers are randomly initialized, so your results below will vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.6269398 , 0.34427637],\n",
       "        [0.21819155, 0.33286617],\n",
       "        [0.23600907, 0.58296105]])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.34042301, 0.89294477, 0.64838042])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.3.2 Evaluating the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP():\n",
    "    def __init__(self,layer_sizes): #<1>\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.weights = [\n",
    "            np.random.rand(n,m) #<2>\n",
    "            for m,n in zip(layer_sizes[:-1],layer_sizes[1:]) #<3>\n",
    "        ]\n",
    "        self.biases = [np.random.rand(n) for n in layer_sizes[1:]] #<4>\n",
    "    def feedforward(self,v):\n",
    "        activations = [] #<1>\n",
    "        a = v\n",
    "        activations.append(a) #<2>\n",
    "        for w,b in zip(self.weights, self.biases): #<3>\n",
    "            z = w @ a + b #<4>\n",
    "            a = [sigmoid(x) for x in z] #<5>\n",
    "            activations.append(a) #<6>\n",
    "        return activations\n",
    "    def evaluate(self,v):\n",
    "        return np.array(self.feedforward(v)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.3.3 Testing the classification performance of an MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLP([64,16,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.matrix.flatten(digits.images[0]) / 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99767547, 0.99967326, 0.99948573, 0.99996856, 0.99991776,\n",
       "       0.99978748, 0.99957805, 0.99822757, 0.99950808, 0.99995966])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.evaluate(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.104"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digit_classify(nn.evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.3.4 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16.4 Training a neural network using gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.4.1 Framing training as a minimization problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.4.2 Calculating gradients with backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.4.3 Automatic training with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([np.matrix.flatten(img) for img in digits.images[:1000]]) / 15.0\n",
    "y = digits.target[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(16,), #<1>\n",
    "                    activation='logistic', #<2>\n",
    "                    max_iter=100, #<3>\n",
    "                    verbose=10, #<4>\n",
    "                    random_state=1, #<5>\n",
    "                    learning_rate_init=.1) #<6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.21958598\n",
      "Iteration 2, loss = 1.56912978\n",
      "Iteration 3, loss = 0.98970277\n",
      "Iteration 4, loss = 0.57473464\n",
      "Iteration 5, loss = 0.34048448\n",
      "Iteration 6, loss = 0.21495855\n",
      "Iteration 7, loss = 0.14366771\n",
      "Iteration 8, loss = 0.11077020\n",
      "Iteration 9, loss = 0.08764273\n",
      "Iteration 10, loss = 0.07193546\n",
      "Iteration 11, loss = 0.06020348\n",
      "Iteration 12, loss = 0.04961899\n",
      "Iteration 13, loss = 0.03979645\n",
      "Iteration 14, loss = 0.03334502\n",
      "Iteration 15, loss = 0.02996006\n",
      "Iteration 16, loss = 0.02603968\n",
      "Iteration 17, loss = 0.02355514\n",
      "Iteration 18, loss = 0.02137348\n",
      "Iteration 19, loss = 0.01967878\n",
      "Iteration 20, loss = 0.01751214\n",
      "Iteration 21, loss = 0.01617330\n",
      "Iteration 22, loss = 0.01460386\n",
      "Iteration 23, loss = 0.01408517\n",
      "Iteration 24, loss = 0.01270504\n",
      "Iteration 25, loss = 0.01191634\n",
      "Iteration 26, loss = 0.01114222\n",
      "Iteration 27, loss = 0.01045989\n",
      "Iteration 28, loss = 0.00983648\n",
      "Iteration 29, loss = 0.00920912\n",
      "Iteration 30, loss = 0.00890851\n",
      "Iteration 31, loss = 0.00843426\n",
      "Iteration 32, loss = 0.00796039\n",
      "Iteration 33, loss = 0.00749839\n",
      "Iteration 34, loss = 0.00726271\n",
      "Iteration 35, loss = 0.00673963\n",
      "Iteration 36, loss = 0.00655405\n",
      "Iteration 37, loss = 0.00626207\n",
      "Iteration 38, loss = 0.00600639\n",
      "Iteration 39, loss = 0.00581857\n",
      "Iteration 40, loss = 0.00557529\n",
      "Iteration 41, loss = 0.00533573\n",
      "Iteration 42, loss = 0.00519479\n",
      "Iteration 43, loss = 0.00505128\n",
      "Iteration 44, loss = 0.00490121\n",
      "Iteration 45, loss = 0.00469161\n",
      "Iteration 46, loss = 0.00459590\n",
      "Iteration 47, loss = 0.00464844\n",
      "Iteration 48, loss = 0.00445157\n",
      "Iteration 49, loss = 0.00425515\n",
      "Iteration 50, loss = 0.00424934\n",
      "Iteration 51, loss = 0.00397800\n",
      "Iteration 52, loss = 0.00399927\n",
      "Iteration 53, loss = 0.00383932\n",
      "Iteration 54, loss = 0.00372439\n",
      "Iteration 55, loss = 0.00361744\n",
      "Iteration 56, loss = 0.00356447\n",
      "Iteration 57, loss = 0.00345899\n",
      "Iteration 58, loss = 0.00336792\n",
      "Iteration 59, loss = 0.00330330\n",
      "Iteration 60, loss = 0.00321734\n",
      "Iteration 61, loss = 0.00315784\n",
      "Iteration 62, loss = 0.00309975\n",
      "Iteration 63, loss = 0.00303268\n",
      "Iteration 64, loss = 0.00298242\n",
      "Iteration 65, loss = 0.00294143\n",
      "Iteration 66, loss = 0.00288273\n",
      "Iteration 67, loss = 0.00282763\n",
      "Iteration 68, loss = 0.00277049\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(16,),\n",
       "              learning_rate_init=0.1, max_iter=100, random_state=1, verbose=10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MLPClassifier' object has no attribute '_predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-abe8b951cd32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'MLPClassifier' object has no attribute '_predict'"
     ]
    }
   ],
   "source": [
    "mlp._predict(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_trained_classify(v):\n",
    "    return mlp._predict([v])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MLPClassifier' object has no attribute '_predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-81fba33130ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_digit_classify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msklearn_trained_classify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-fe011c472c8b>\u001b[0m in \u001b[0;36mtest_digit_classify\u001b[1;34m(classifier, test_count)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdigits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtest_count\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtest_count\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#<2>\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m15.\u001b[0m \u001b[1;31m#<3>\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#<4>\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#<5>\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-27479d3f45fc>\u001b[0m in \u001b[0;36msklearn_trained_classify\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msklearn_trained_classify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'MLPClassifier' object has no attribute '_predict'"
     ]
    }
   ],
   "source": [
    "test_digit_classify(sklearn_trained_classify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.4.4 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Modify the `test_digit_classify` function to work on a custom range of examples in the test set.  How does it do on the next 500 examples after the 1,000 training examples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_digit_classify(classifier,start=0,test_count=1000):\n",
    "    correct = 0\n",
    "    end = start + test_count #<1>\n",
    "    for img, target in zip(digits.images[start:end], digits.target[start:end]): #<2>\n",
    "        v = np.matrix.flatten(img) / 15.\n",
    "        output = classifier(v)\n",
    "        answer = list(output).index(max(output))\n",
    "        if answer == target:\n",
    "            correct += 1\n",
    "    return (correct/test_count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MLPClassifier' object has no attribute '_predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-ffe7a4df7280>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_digit_classify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msklearn_trained_classify\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-9861669cdbfc>\u001b[0m in \u001b[0;36mtest_digit_classify\u001b[1;34m(classifier, start, test_count)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdigits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#<2>\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m15.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-27479d3f45fc>\u001b[0m in \u001b[0;36msklearn_trained_classify\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msklearn_trained_classify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'MLPClassifier' object has no attribute '_predict'"
     ]
    }
   ],
   "source": [
    "test_digit_classify(sklearn_trained_classify,start=1000,test_count=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Using the squared distance cost function, what is the cost of your randomly-generated MLP for the first 1,000 training examples?  What is the cost of the scikit-learn MLP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_vec(digit):\n",
    "    return np.array([1 if i == digit else 0 for i in range(0,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_one(classifier,x,i):\n",
    "    return sum([(classifier(x)[j] - y_vec(i)[j])**2 for j in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_cost(classifier):\n",
    "    return sum([cost_one(classifier,x[j],y[j]) for j in range(1000)])/1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.990834701722013"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cost(nn.evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.670512721637246e-05"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cost(sklearn_trained_classify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mini-project:** Extract the MLPClassifier weights and biases using its properties called `coefs_` and `intercepts_`, respectively.  Plug these weights and biases into the MLP class we built from scratch and show that your resulting MLP performs well on digit classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLP([64,16,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.weights = [w.T for w in mlp.coefs_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.biases = mlp.intercepts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.962"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digit_classify(nn.evaluate,start=1000,test_count=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16.5 Calculating gradients with backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.5.1 Finding the cost in terms of the last layer weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.5.1 Finding the cost in terms of the last layer weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.5.2 Calculating the partial derivatives for the last layer weights using the chain rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.5.3 Exercises "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mini-project:** Use SymPy or your own code from chapter 10 to automatically find the derivative of the sigmoid function:\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "Show that the answer you get is equal to $\\sigma(x)(1-\\sigma(x))$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exp(-x)/(1 + exp(-x))**2"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import *\n",
    "X = symbols('x')\n",
    "diff(1 / (1+exp(-X)),X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
